{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DKBYgFFZ85X9pAh9u5sJoYeLcEnz_xtx",
      "authorship_tag": "ABX9TyNcGiJLrHid6I/WsXgm73Rp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohan30497/EEG_Signal_Processing/blob/main/EEG_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvK97ZAukajn",
        "outputId": "ca7395f0-059a-430e-82db-1d04cd9396c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.5.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (3.11.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.5.1\n"
          ]
        }
      ],
      "source": [
        "  pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n"
      ],
      "metadata": {
        "id": "wMfgPl99lNpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_file_path=glob('/content/drive/MyDrive/data_files/*.set')\n",
        "print(len(all_file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkAe-TNrllQu",
        "outputId": "29acc8a3-98bf-4b2b-f56f-11cd7018a052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_file_path = [i for i in all_file_path if 'C' in i]\n",
        "len(healthy_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilDyx9TjqiBk",
        "outputId": "13ded03d-8359-4952-c0d0-f63dbd82f199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patient_file_path = [i for i in all_file_path if 'A' in i]\n",
        "len(patient_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VXFuTGvquiW",
        "outputId": "2109138c-d57c-492c-e2c4-e41429b0b554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_path):\n",
        "    data = mne.io.read_raw_eeglab(file_path, preload=True)\n",
        "    data.set_eeg_reference()\n",
        "    data.filter(l_freq=0.5, h_freq=45)\n",
        "    epochs = mne.make_fixed_length_epochs(data, duration=5, overlap=1)\n",
        "    array = epochs.get_data()\n",
        "    return array"
      ],
      "metadata": {
        "id": "ykJfmfthrak2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = read_data(healthy_file_path[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll_1qcjltaDA",
        "outputId": "7cddc54a-b42f-41ad-ba93-f594c8876541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG channel type selected for re-referencing\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 45 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 45.00 Hz\n",
            "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
            "- Filter length: 3301 samples (6.602 s)\n",
            "\n",
            "Not setting metadata\n",
            "194 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 194 events and 2500 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_data.shape) #no.of epochs,no.of channels,length of signal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iAz3aj-txtU",
        "outputId": "b998e4b8-a0e2-4ed5-845a-3c7263b99430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(194, 19, 2500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "control_epochs_array=[read_data(i) for i in healthy_file_path]\n",
        "patient_epochs_array=[read_data(i) for i in patient_file_path]"
      ],
      "metadata": {
        "id": "haCdtxX7uEA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "\n",
        "def read_data(file_path):\n",
        "    try:\n",
        "        if file_path.endswith('.set'):\n",
        "            data = mne.io.read_raw_eeglab(file_path, preload=True)\n",
        "        elif file_path.endswith('.mat'):\n",
        "            # Read the MATLAB .mat file using mne.io.read_raw_eeglab\n",
        "            data = mne.io.read_raw_eeglab(file_path, preload=True)\n",
        "\n",
        "        data.set_eeg_reference()\n",
        "        data.filter(l_freq=0.5, h_freq=45)\n",
        "        epochs = mne.make_fixed_length_epochs(data, duration=5, overlap=1)\n",
        "        array = epochs.get_data()\n",
        "        return array\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file: {file_path}\")\n",
        "        print(f\"Error message: {str(e)}\")\n",
        "        return []  # Return an empty list if there is an error\n"
      ],
      "metadata": {
        "id": "jx_BsfnOx5hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "control_epochs_array[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCWp-mlSytnP",
        "outputId": "41ca85d2-d71e-453e-893a-a8bd539a9e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(194, 19, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patient_epochs_array[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKmFrwKp0p0d",
        "outputId": "3b1c6f3a-d358-459a-fe89-da64e6c2ff4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(198, 19, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "control_epochs_labels=[len(i)*[0] for i in control_epochs_array]\n"
      ],
      "metadata": {
        "id": "CXpQnRQX2YT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_epochs_labels=[len(i)*[1] for i in patient_epochs_array]"
      ],
      "metadata": {
        "id": "ImtdfQS_3JDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list=patient_epochs_array+control_epochs_array\n",
        "label_list=patient_epochs_labels+control_epochs_labels"
      ],
      "metadata": {
        "id": "86YCAvwt4WlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_list=[[i]*len(j) for i,j in enumerate(data_list)]"
      ],
      "metadata": {
        "id": "1QMs7Zrf4YSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWxlRD70INvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming patient_epochs_array and control_epochs_array contain the EEG data arrays\n",
        "\n",
        "# Ensure patient_epochs_array contains only 3-dimensional arrays (excluding the first element)\n",
        "patient_epochs_array_3d = [array for array in patient_epochs_array if isinstance(array, np.ndarray) and array.ndim == 3]\n",
        "\n",
        "# Ensure control_epochs_array contains only 3-dimensional arrays\n",
        "control_epochs_array_3d = [array for array in control_epochs_array if array.ndim == 3]\n",
        "\n",
        "# Combine the patient and control arrays\n",
        "data_list = patient_epochs_array_3d[0:] + control_epochs_array_3d\n",
        "\n",
        "# Vertically stack the arrays\n",
        "data_array = np.vstack(data_list)\n"
      ],
      "metadata": {
        "id": "NWc6wQ7YJdLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_array=np.hstack(label_list)\n",
        "group_array=np.hstack(group_list)"
      ],
      "metadata": {
        "id": "D3OdoFEgJmkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array.shape,label_array.shape,group_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7newRXibKloP",
        "outputId": "2e8ca312-6d93-421d-efed-648126d9f3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4515, 19, 2500), (4515,), (4515,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the mean of the signal\n",
        "def calculate_mean(signal):\n",
        "    return np.mean(signal, axis=-1)\n",
        "\n",
        "# Function to calculate the standard deviation of the signal\n",
        "def calculate_std(signal):\n",
        "    return np.std(signal, axis=-1)\n",
        "\n",
        "# Function to calculate the range (peak-to-peak) of the signal\n",
        "def calculate_ptp(signal):\n",
        "    return np.ptp(signal, axis=-1)\n",
        "\n",
        "# Function to calculate the variance of the signal\n",
        "def calculate_variance(signal):\n",
        "    return np.var(signal, axis=-1)\n",
        "\n",
        "# Function to calculate the minimum value of the signal\n",
        "def calculate_minimum(signal):\n",
        "    return np.min(signal, axis=-1)\n",
        "\n",
        "# Function to calculate the maximum value of the signal\n",
        "def calculate_maximum(signal):\n",
        "    return np.max(signal, axis=-1)\n",
        "\n",
        "# Function to get the index of the minimum value of the signal\n",
        "def get_argmin(signal):\n",
        "    return np.argmin(signal, axis=-1)\n",
        "\n",
        "# Function to get the index of the maximum value of the signal\n",
        "def get_argmax(signal):\n",
        "    return np.argmax(signal, axis=-1)\n",
        "\n",
        "# Function to calculate the root mean square (RMS) of the signal\n",
        "def calculate_rms(signal):\n",
        "    return np.sqrt(np.mean(signal**2, axis=-1))\n",
        "\n",
        "# Function to calculate the absolute difference between consecutive signal values\n",
        "def calculate_abs_diff_signal(signal):\n",
        "    return np.sum(np.abs(np.diff(signal, axis=-1)), axis=-1)\n",
        "\n",
        "# Function to calculate the skewness of the signal\n",
        "def calculate_skewness(signal):\n",
        "    return stats.skew(signal, axis=-1)\n",
        "\n",
        "# Function to calculate the kurtosis of the signal\n",
        "def calculate_kurtosis(signal):\n",
        "    return stats.kurtosis(signal, axis=-1)\n",
        "\n",
        "def concatenate_features(signal):\n",
        "    # Calculate various features\n",
        "    mean_features = calculate_mean(signal)\n",
        "    std_features = calculate_std(signal)\n",
        "    ptp_features = calculate_ptp(signal)\n",
        "    variance_features = calculate_variance(signal)\n",
        "    minimum_features = calculate_minimum(signal)\n",
        "    maximum_features = calculate_maximum(signal)\n",
        "    argmin_features = get_argmin(signal)\n",
        "    argmax_features = get_argmax(signal)\n",
        "    rms_features = calculate_rms(signal)\n",
        "    abs_diff_signal_features = calculate_abs_diff_signal(signal)\n",
        "    skewness_features = calculate_skewness(signal)\n",
        "    kurtosis_features = calculate_kurtosis(signal)\n",
        "\n",
        "    # Concatenate all the features using np.concatenate\n",
        "    concatenated_features = np.concatenate((mean_features, std_features, ptp_features, variance_features, minimum_features,\n",
        "                                             maximum_features, argmin_features, argmax_features, rms_features,\n",
        "                                             abs_diff_signal_features, skewness_features, kurtosis_features), axis=-1)\n",
        "    return concatenated_features\n",
        "\n",
        "features = []\n",
        "for d in data_array:\n",
        "    features.append(concatenate_features(d))\n"
      ],
      "metadata": {
        "id": "SyElkw98KpCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_array=np.array(features)\n",
        "features_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "QGiZiZ1WOwKy",
        "outputId": "f82176d1-3118-47c6-bb4d-eabd89513896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-32a1c1ebb0fc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the LogisticRegression classifier\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Define the GroupKFold cross-validator\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "# Define the pipeline with steps\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', clf)\n",
        "])\n",
        "\n",
        "# Define the parameter grid for the GridSearchCV\n",
        "param_grid = {'clf__C': [0.1, 0.5, 0.7, 1, 3, 7]}\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "gscv = GridSearchCV(pipe, param_grid, cv=gkf, n_jobs=12, scoring='accuracy')  # Use the desired scoring metric\n",
        "\n",
        "# Fit the GridSearchCV with the data\n",
        "gscv.fit(features_array, label_array, groups=group_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "mIFz6Ka2TedD",
        "outputId": "49437a2c-bf0b-4dbb-def0-3ca035a5a8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=GroupKFold(n_splits=5),\n",
              "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                       ('clf', LogisticRegression())]),\n",
              "             n_jobs=12, param_grid={'clf__C': [0.1, 0.5, 0.7, 1, 3, 7]},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=GroupKFold(n_splits=5),\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=12, param_grid={&#x27;clf__C&#x27;: [0.1, 0.5, 0.7, 1, 3, 7]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=GroupKFold(n_splits=5),\n",
              "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
              "             n_jobs=12, param_grid={&#x27;clf__C&#x27;: [0.1, 0.5, 0.7, 1, 3, 7]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hBnZIDHWoyq",
        "outputId": "317d876e-dd07-4467-ac60-7dccf20521b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2729,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Implementation of CNN**"
      ],
      "metadata": {
        "id": "fxdWNJ96Yrvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#epochs_array=data_array\n",
        "#epochs_labels=label_array\n",
        "#group_array"
      ],
      "metadata": {
        "id": "wwSIgEZHKTSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array=np.moveaxis(data_array,1,2)\n",
        "data_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA2a36x0K5-H",
        "outputId": "1a110453-2dec-4ae2-e6bf-dc8093bd83eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4515, 2500, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(2500, 19)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5atGZvFvL1-B",
        "outputId": "7e4ba010-1013-4146-dfcf-b57faf6c77bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 2498, 64)          3712      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 1249, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 79936)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 319748    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 323,465\n",
            "Trainable params: 323,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "\n",
        "model_1 = Sequential()\n",
        "# Block 1\n",
        "model_1.add(Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=(2500, 19)))\n",
        "model_1.add(Conv1D(64, kernel_size=3, activation='relu', padding='same'))\n",
        "model_1.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Block 2\n",
        "model_1.add(Conv1D(128, kernel_size=3, activation='relu', padding='same'))\n",
        "model_1.add(Conv1D(128, kernel_size=3, activation='relu', padding='same'))\n",
        "model_1.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Block 3\n",
        "model_1.add(Conv1D(256, kernel_size=3, activation='relu', padding='same'))\n",
        "model_1.add(Conv1D(256, kernel_size=3, activation='relu', padding='same'))\n",
        "model_1.add(Conv1D(256, kernel_size=3, activation='relu', padding='same'))\n",
        "model_1.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(256, activation='relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc2jZzsLI0hd",
        "outputId": "e93b2010-bec8-48de-bbec-15130bc80f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 2500, 64)          3712      \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 2500, 64)          12352     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1250, 64)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 1250, 128)         49280     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 625, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 625, 256)          98560     \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 625, 256)          196864    \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 625, 256)          196864    \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 312, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 79872)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               20447488  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,030,081\n",
            "Trainable params: 21,030,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "gkf = GroupKFold(n_splits=3)"
      ],
      "metadata": {
        "id": "uzDLBcS9N3Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store accuracy values for each split\n",
        "accuracy_train = []\n",
        "accuracy_val = []\n",
        "accuracy_test = []\n",
        "\n",
        "for train_index, val_test_index in gkf.split(data_array, label_array, group_array):\n",
        "    # Split into training and validation/test sets\n",
        "    train_features, train_labels = data_array[train_index], label_array[train_index]\n",
        "    val_test_features, val_test_labels = data_array[val_test_index], label_array[val_test_index]\n",
        "\n",
        "    # Further split the validation/test set into validation and test sets\n",
        "    val_index, test_index = next(GroupKFold(n_splits=2).split(val_test_features, val_test_labels, group_array[val_test_index]))\n",
        "    val_features, val_labels = val_test_features[val_index], val_test_labels[val_index]\n",
        "    test_features, test_labels = val_test_features[test_index], val_test_labels[test_index]\n",
        "\n",
        "    # Standardize the data using the same scaler for training, validation, and test sets\n",
        "    scaler = StandardScaler()\n",
        "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
        "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
        "    test_features = scaler.transform(test_features.reshape(-1, test_features.shape[-1])).reshape(test_features.shape)"
      ],
      "metadata": {
        "id": "9UlOfJcjpf_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Fit the model on the training data\n",
        "model.fit(train_features, train_labels, epochs=5, batch_size=50, validation_data=(val_features, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkuVgV2Lq0dw",
        "outputId": "ac1308dd-5b01-4816-99ca-a49b3a7c3c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "60/60 [==============================] - 13s 31ms/step - loss: 0.5353 - accuracy: 0.8465 - val_loss: 0.5186 - val_accuracy: 0.7587\n",
            "Epoch 2/5\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 0.4069 - accuracy: 0.8545 - val_loss: 0.6876 - val_accuracy: 0.7587\n",
            "Epoch 3/5\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 0.3946 - accuracy: 0.8545 - val_loss: 1.0803 - val_accuracy: 0.7587\n",
            "Epoch 4/5\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 0.3738 - accuracy: 0.8545 - val_loss: 1.2457 - val_accuracy: 0.7587\n",
            "Epoch 5/5\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 0.3800 - accuracy: 0.8545 - val_loss: 1.2101 - val_accuracy: 0.7587\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b8de8a13760>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation and test data\n",
        "_, acc_train = model.evaluate(train_features, train_labels)\n",
        "_, acc_val = model.evaluate(val_features, val_labels)\n",
        "_, acc_test = model.evaluate(test_features, test_labels)\n",
        "\n",
        "accuracy_train.append(acc_train)\n",
        "accuracy_val.append(acc_val)\n",
        "accuracy_test.append(acc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5PY1XnjrOdc",
        "outputId": "0518decb-992e-4c7b-fe8d-9f4daff8e50d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 1s 6ms/step - loss: 0.1420 - accuracy: 0.8545\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 1.2101 - accuracy: 0.7587\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6866 - accuracy: 0.6690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the VGGNet16 architecture"
      ],
      "metadata": {
        "id": "tzUz1Qs73NbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "for train_index, val_index in gkf.split(data_array, label_array, group_array):\n",
        "    train_features, train_labels = data_array[train_index], label_array[train_index]\n",
        "    val_features, val_labels = data_array[val_index], label_array[val_index]\n",
        "    scaler = StandardScaler()\n",
        "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
        "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
        "        # Fit the model\n",
        "    model.fit(train_features, train_labels, epochs=5, batch_size=50, validation_data=(val_features, val_labels))\n",
        "    _, acc = model.evaluate(val_features, val_labels)\n",
        "    accuracy.append(acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxhqPIJMOee0",
        "outputId": "a4afee2c-2331-47da-d7f2-68b0ac14190b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "73/73 [==============================] - 25s 299ms/step - loss: 0.7272 - accuracy: 0.7561 - val_loss: 0.6608 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "73/73 [==============================] - 21s 282ms/step - loss: 0.6684 - accuracy: 0.7605 - val_loss: 0.6281 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "73/73 [==============================] - 21s 284ms/step - loss: 0.6529 - accuracy: 0.7608 - val_loss: 0.5978 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "73/73 [==============================] - 20s 281ms/step - loss: 0.6393 - accuracy: 0.7608 - val_loss: 0.5699 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "73/73 [==============================] - 20s 278ms/step - loss: 0.6274 - accuracy: 0.7605 - val_loss: 0.5441 - val_accuracy: 1.0000\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 0.5441 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "74/74 [==============================] - 20s 269ms/step - loss: 0.5940 - accuracy: 0.8203 - val_loss: 0.6110 - val_accuracy: 0.7541\n",
            "Epoch 2/5\n",
            "74/74 [==============================] - 20s 274ms/step - loss: 0.5777 - accuracy: 0.8203 - val_loss: 0.6007 - val_accuracy: 0.7541\n",
            "Epoch 3/5\n",
            "74/74 [==============================] - 22s 303ms/step - loss: 0.5636 - accuracy: 0.8203 - val_loss: 0.5920 - val_accuracy: 0.7541\n",
            "Epoch 4/5\n",
            "74/74 [==============================] - 20s 268ms/step - loss: 0.5515 - accuracy: 0.8203 - val_loss: 0.5848 - val_accuracy: 0.7541\n",
            "Epoch 5/5\n",
            "74/74 [==============================] - 20s 273ms/step - loss: 0.5408 - accuracy: 0.8203 - val_loss: 0.5789 - val_accuracy: 0.7541\n",
            "27/27 [==============================] - 1s 37ms/step - loss: 0.5789 - accuracy: 0.7541\n",
            "Epoch 1/5\n",
            "72/72 [==============================] - 21s 290ms/step - loss: 0.5280 - accuracy: 0.8253 - val_loss: 0.5846 - val_accuracy: 0.7397\n",
            "Epoch 2/5\n",
            "72/72 [==============================] - 20s 274ms/step - loss: 0.5200 - accuracy: 0.8250 - val_loss: 0.5812 - val_accuracy: 0.7397\n",
            "Epoch 3/5\n",
            "72/72 [==============================] - 22s 306ms/step - loss: 0.5127 - accuracy: 0.8250 - val_loss: 0.5787 - val_accuracy: 0.7397\n",
            "Epoch 4/5\n",
            "72/72 [==============================] - 22s 304ms/step - loss: 0.5063 - accuracy: 0.8250 - val_loss: 0.5767 - val_accuracy: 0.7397\n",
            "Epoch 5/5\n",
            "72/72 [==============================] - 24s 333ms/step - loss: 0.5003 - accuracy: 0.8253 - val_loss: 0.5752 - val_accuracy: 0.7397\n",
            "29/29 [==============================] - 3s 88ms/step - loss: 0.5752 - accuracy: 0.7397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM\n",
        "from keras.layers import Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "\n",
        "\n",
        "# Now, let's build the combined LSTM-CNN model\n",
        "combined_model = Sequential()\n",
        "\n",
        "# Add the CNN layers from your existing model\n",
        "combined_model.add(model)\n",
        "\n",
        "# Reshape the output of the CNN to match LSTM input\n",
        "combined_model.add(Reshape((model.output_shape[1], 1)))\n",
        "\n",
        "# Add the LSTM layer on top with return_sequences=False and 32 units\n",
        "combined_model.add(LSTM(32, return_sequences=False))\n",
        "\n",
        "# Compile the combined model\n",
        "custom_optimizer = Adam(learning_rate=0.01)\n",
        "combined_model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the combined model summary\n",
        "combined_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6df3x-ghIPiQ",
        "outputId": "669f8ee5-d42a-4422-8971-8afb5b655e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 1)                 323465    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 1, 1)              0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                4352      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 327,817\n",
            "Trainable params: 327,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store accuracy values for each split\n",
        "accuracy_train = []\n",
        "accuracy_val = []\n",
        "accuracy_test = []\n",
        "\n",
        "for train_index, val_test_index in gkf.split(data_array, label_array, group_array):\n",
        "    # Split into training and validation/test sets\n",
        "    train_features, train_labels = data_array[train_index], label_array[train_index]\n",
        "    val_test_features, val_test_labels = data_array[val_test_index], label_array[val_test_index]\n",
        "\n",
        "    # Further split the validation/test set into validation and test sets\n",
        "    val_index, test_index = next(GroupKFold(n_splits=2).split(val_test_features, val_test_labels, group_array[val_test_index]))\n",
        "    val_features, val_labels = val_test_features[val_index], val_test_labels[val_index]\n",
        "    test_features, test_labels = val_test_features[test_index], val_test_labels[test_index]\n",
        "\n",
        "    # Standardize the data using the same scaler for training, validation, and test sets\n",
        "    scaler = StandardScaler()\n",
        "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
        "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
        "    test_features = scaler.transform(test_features.reshape(-1, test_features.shape[-1])).reshape(test_features.shape)"
      ],
      "metadata": {
        "id": "SgdWThnwI6Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Fit the model on the training data\n",
        "combined_model.fit(train_features, train_labels, epochs=5, batch_size=50, validation_data=(val_features, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnNSyZH_vYpb",
        "outputId": "3e585a7c-30f5-4b0c-983c-5eabbd7efc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "60/60 [==============================] - 6s 31ms/step - loss: 6.7807 - accuracy: 0.0000e+00 - val_loss: 5.6671 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "60/60 [==============================] - 1s 15ms/step - loss: 6.2862 - accuracy: 0.0000e+00 - val_loss: 5.5227 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 6.1553 - accuracy: 0.0000e+00 - val_loss: 5.4770 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 6.1042 - accuracy: 0.0000e+00 - val_loss: 5.4580 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "60/60 [==============================] - 1s 14ms/step - loss: 6.0780 - accuracy: 0.0000e+00 - val_loss: 5.4484 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b8bf381b100>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation and test data\n",
        "_, acc_train = combined_model.evaluate(train_features, train_labels)\n",
        "_, acc_val = combined_model.evaluate(val_features, val_labels)\n",
        "_, acc_test = combined_model.evaluate(test_features, test_labels)\n",
        "\n",
        "accuracy_train.append(acc_train)\n",
        "accuracy_val.append(acc_val)\n",
        "accuracy_test.append(acc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkrEejoUv94r",
        "outputId": "5c774bf6-1e0c-4d24-8e42-238e225b66a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 1s 7ms/step - loss: 6.0625 - accuracy: 0.0000e+00\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 5.4484 - accuracy: 0.0000e+00\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 4.8731 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_oQrPgx60ld"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}